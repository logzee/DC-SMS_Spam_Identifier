# -*- coding: utf-8 -*-
"""
Created on Sat Feb 29 09:23:59 2020
@author: Courtney
"""
import pandas as pd
import numpy as np
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
from nltk import word_tokenize
from nltk import WordNetLemmatizer
import string
from sklearn.linear_model.logistic import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score
from DC7.DC7new import clean_text, stematize_sentence, term_count, term_frequency, inverse_document_frequency, tf_idf

# Preping the Data
path = '/Users/alinajam/Desktop/smsspamcollection/SMSSpamCollection.csv'
df = pd.read_csv(path, engine = 'python')


rowIndex = 0
docFrequences = []
for article in df.iloc[:, 9]:
    processedArticle = clean_text(article)
    processedArticle = stematize_sentence(processedArticle)
    processedArticle = clean_text(processedArticle)
    processedArticle = stematize_sentence(processedArticle)
    df.iloc[rowIndex, 9] = processedArticle
    rowIndex += 1

TF_IDF_Features = tf_idf(df.iloc[:, 9])
df['TF-IDF features'] = TF_IDF_Features
print(df)

train_x, test_x, train_y, test_y = train_test_split(df[1], df[0])

classifier = LogisticRegression()
classifier.fit(train_x, train_y)
